{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_save_and_load.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38qjn4RdkACU"
      },
      "source": [
        "## What is state_dict?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hAxkuJVmAPr"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5N3Hweaj5n-",
        "outputId": "4ce8e2e9-c28a-46dc-9a41-79a1814da776"
      },
      "source": [
        "# define model\r\n",
        "\r\n",
        "class TheModelClass(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(TheModelClass, self).__init__()\r\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "    self.pool = nn.MaxPool2d(2, 2)\r\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n",
        "    self.fc2 = nn.Linear(120, 84)\r\n",
        "    self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.pool(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool(F.relu(self.conv2(x)))\r\n",
        "    x = x.view(-1, 16 * 5 * 5)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.fc3(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "# model 초기화\r\n",
        "model = TheModelClass()\r\n",
        "\r\n",
        "# optimizer 초기화\r\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\r\n",
        "\r\n",
        "# model의 state_dict 출력\r\n",
        "print(\"Model's state_dict : \")\r\n",
        "for param_tensor in model.state_dict():\r\n",
        "  print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\r\n",
        "\r\n",
        "# optimizer의 state_dict 출력\r\n",
        "print(\"Optimizer's state_dict : \")\r\n",
        "for var_name in optimizer.state_dict():\r\n",
        "  print(var_name, '\\t', optimizer.state_dict()[var_name])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict : \n",
            "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
            "conv1.bias \t torch.Size([6])\n",
            "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
            "conv2.bias \t torch.Size([16])\n",
            "fc1.weight \t torch.Size([120, 400])\n",
            "fc1.bias \t torch.Size([120])\n",
            "fc2.weight \t torch.Size([84, 120])\n",
            "fc2.bias \t torch.Size([84])\n",
            "fc3.weight \t torch.Size([10, 84])\n",
            "fc3.bias \t torch.Size([10])\n",
            "Optimizer's state_dict : \n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxLgbzijpH5L"
      },
      "source": [
        "### 추론을 위해 state_dict 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZEjgW3Ko-Uh"
      },
      "source": [
        "# state_dict 저장\r\n",
        "torch.save(model.state_dict(), PATH)\r\n",
        "\r\n",
        "# state_dict 불러오기\r\n",
        "model = TheModelClass(*args, **kwargs)\r\n",
        "model.load_state_dict(torch.load(PATH))\r\n",
        "model.eval() # 평가 모드로 설정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP7gC3ZRptaV"
      },
      "source": [
        "### 추론을 위해 전체 모델 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDE0wPpJp2bS"
      },
      "source": [
        "# model 저장\r\n",
        "torch.save(model, PATH)\r\n",
        "\r\n",
        "# model 불러오기\r\n",
        "model = torch.load(PATH) # model class는 어디엔가 반드시 선언되어 있어야 한다\r\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBbNhCgRGgZR"
      },
      "source": [
        "### 추론/학습 재개를 위해 일반 체크포인트 저장하기 & 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVe66Q34GoTf"
      },
      "source": [
        "# checkpoint 저장하기\r\n",
        "torch.save({\r\n",
        "    'epoch' : epoch,\r\n",
        "    'model_state_dict' : model.state_dict(),\r\n",
        "    'optimizer_state_dict' : optimizer.state_dict(),\r\n",
        "    'loss' : loss,\r\n",
        "    ...\r\n",
        "}, PATH)\r\n",
        "\r\n",
        "# checkpoint 불러오기\r\n",
        "model = TheModelClass(*args, **kwargs)\r\n",
        "optimizer = TheOptimizerClass(*args, **kwargs)\r\n",
        "\r\n",
        "checkpoint = torch.load(PATH)\r\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "epoch = checkpoint['epoch']\r\n",
        "loss = checkpoint['loss']\r\n",
        "\r\n",
        "# 필요에 따라 바꿔 쓰기\r\n",
        "model.eval()\r\n",
        "# model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GrkGWU2JY-F"
      },
      "source": [
        "### 여러 개의 모델을 하나의 파일에 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGowPx_PJfmi"
      },
      "source": [
        "# model 저장하기\r\n",
        "torch.save({\r\n",
        "    'modelA_state_dict' : modelA.state_dict(),\r\n",
        "    'modelB_state_dict' : modelB.state_dict(),\r\n",
        "    'optimizerA' : optimizerA.state_dict(),\r\n",
        "    'optimizerB' : optimizerB.state_dict(),\r\n",
        "    ...\r\n",
        "}, PATH)\r\n",
        "\r\n",
        "# model 불러오기\r\n",
        "modelA = TheModelAClass(*args, **kwargs)\r\n",
        "modelB = TheModelBClass(*args, **kwargs)\r\n",
        "optimizerA = TheOptimizerAClass(*args, **kwargs)\r\n",
        "optimizerB = TheOptimizerBClass(*args, **kwargs)\r\n",
        "\r\n",
        "checkpoint = torch.load(PATH)\r\n",
        "modelA.load_state_dict(checkpoint['modelA_state_dict'])\r\n",
        "modelB.load_state_dict(checkpoint['modelB_state_dict'])\r\n",
        "optimizerA.load_state_dict(chckpoint['optimizerA_state_dict'])\r\n",
        "optimizerB.load_state_dict(chckpoint['optimizerB_state_dict'])\r\n",
        "\r\n",
        "# 필요에 따라 바꿔 쓰기\r\n",
        "modelA.eval()\r\n",
        "modelB.eval()\r\n",
        "# modelA.train()\r\n",
        "# modelB.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg3ArivFLkJ5"
      },
      "source": [
        "### 다른 모델의 메개변수를 사용해 빠르게 모델 시작하기(warmstart)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdtZFnJBMI3A"
      },
      "source": [
        "# comming soon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsEOESAeLtUW"
      },
      "source": [
        "### 장치 간 모델 저장 및 불러오기(GPU에서 저장, CPU에서 불러오기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a54l9vwZMJYB"
      },
      "source": [
        "# comming soon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5BtvZWmL5LO"
      },
      "source": [
        "### 장치 간 모델 저장 및 불러오기(CPU에서 저장, GPU에서 불러오기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKSxT-8MJ2_"
      },
      "source": [
        "# comming soon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmlEhlEAMCxX"
      },
      "source": [
        "### torch.nn.DataParallel 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr6xki0gMKlJ"
      },
      "source": [
        "# comming soon"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}